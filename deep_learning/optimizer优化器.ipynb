{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 需要了解的知识：\n",
    "# 指数移动平均EMA: w_t = βw_t-1+（1-β） \n",
    "\n",
    "class EMA():\n",
    "    def __init__(self, decay):\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    " \n",
    "    def register(self, name, val):\n",
    "        self.shadow[name] = val\n",
    " \n",
    "    def get(self, name):\n",
    "        return self.shadow[name]\n",
    " \n",
    "    def update(self, name, x):\n",
    "        assert name in self.shadow\n",
    "        new_average = (1.0 - self.decay) * x + self.decay * self.shadow[name]\n",
    "        print(new_average)\n",
    "        self.shadow[name] = new_average\n",
    "        \n",
    "# 参考：https://blog.csdn.net/apodx/article/details/124646664       \n",
    "              \n",
    "class EMA:\n",
    "    def __init__(self,delay):\n",
    "        self.decay = decay\n",
    "        self.pre_w = {}\n",
    "        \n",
    "    def update(self, name, x):\n",
    "        if 'name' not in self.pre_w:\n",
    "            self.pre_w[name] = x\n",
    "        ema = (1.0 - self.decay) * x + self.decay * self.pre_w[name]\n",
    "        print(ema)\n",
    "        self.pre_w[name] = ema\n",
    "\n",
    "        \n",
    "# 带偏差修正的指数加权平均\n",
    "'''\n",
    "在机器学习中，多数的指数加权平均运算并不会使用偏差修正。因为大多数人更愿意在初始阶段，用一个捎带偏差的值进行运算。\n",
    "不过，如果在初试阶段就开始考虑偏差，指数加权移动均值仍处于预热阶段，偏差修正可以做出更好的估计。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD 随机梯度下降: w = w-lr*grad(w)\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self,lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self,params,grads):\n",
    "        for key in params.key():\n",
    "            params[key] -= self.lr*grads[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用d2l画图\n",
    "from d2l import torch as d2l\n",
    "\n",
    "# 参考：https://blog.csdn.net/tcn760/article/details/123965374\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# momentum\n",
    "class Momentum:\n",
    "    def __init__(self,lr,β=0.9):\n",
    "        self.lr = lr\n",
    "        self.β = β\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self,params,grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():  # 开始先初始化为0，后面是遇到相同的key进行更新即迭代的时候更新\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "            \n",
    "        for key in params.key():         \n",
    "            self.v[key] =  self.β*self.v[key] + self.lr*grads[key]\n",
    "            params[key] -= self.v[key] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adagrad:引入了过去的梯度的平方之和进行优化\n",
    "class Momentum:\n",
    "    def __init__(self,lr):\n",
    "        self.lr = lr\n",
    "        self.gg = None\n",
    "        \n",
    "    def update(self,params,grads):\n",
    "        if self.gg is None:\n",
    "            self.gg = {}\n",
    "            for key, val in params.items():  # 开始先初始化为0，后面是遇到相同的key进行更新即迭代的时候更新\n",
    "                self.gg[key] = np.zeros_like(val)\n",
    "            \n",
    "        for key in params.key():         \n",
    "            self.gg[key] += self.grads[key]*self.grads[key]\n",
    "            params[key] -= self.lr*grads[key]/np.sqrt(self.gg[key]+1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSprop:利用了历史梯度的平方的EMA\n",
    "class Momentum:\n",
    "    def __init__(self,lr=0.1,β=0.9):\n",
    "        self.lr = lr\n",
    "        self.β = β\n",
    "        self.v_gg = None\n",
    "        \n",
    "    def update(self,params,grads):\n",
    "        if self.v_gg is None:\n",
    "            self.v_gg = {}\n",
    "            for key, val in params.items():  # 开始先初始化为0，后面是遇到相同的key进行更新即迭代的时候更新\n",
    "                self.v_gg[key] = np.zeros_like(val)\n",
    "            \n",
    "        for key in params.key():         \n",
    "            self.v_gg[key] = self.β* self.v_gg[key]+ (1-self.β)*grads[key]*grads[key]\n",
    "            params[key] -= self.lr*grads[key]/np.sqrt(self.v_gg[key]+1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam:结合了moment和rmsprop\n",
    "class Momentum:\n",
    "    def __init__(self,lr=0.1,β1=0.9,β2=0.999):\n",
    "        self.lr = lr\n",
    "        self.β1 = β1\n",
    "        self.β2 = β2\n",
    "        self.m = None\n",
    "        self.v_gg = None\n",
    "        \n",
    "    def update(self,params,grads):\n",
    "        if self.v_gg  is None:   \n",
    "            self.v_gg = {}\n",
    "            for key, val in params.items():  # 开始先初始化为0，后面是遇到相同的key进行更新即迭代的时候更新\n",
    "                self.v_gg[key] = np.zeros_like(val)\n",
    "        if self.m is None:   \n",
    "            self.m = {}\n",
    "            for key, val in params.items():  # 开始先初始化为0，后面是遇到相同的key进行更新即迭代的时候更新\n",
    "                self.m[key] = np.zeros_like(val)\n",
    "            \n",
    "        for key in params.key():  \n",
    "            self.m[key] = self.β1*self.m[key] + (1-β1)*grads[key]\n",
    "            self.v_gg[key] = self.β2* self.v_gg[key]+ (1-self.β2)*grads[key]*.grads[key]\n",
    "            params[key] -= self.lr*self.m[key]/np.sqrt(self.v_gg[key]+1e-8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
